{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4d04b59",
   "metadata": {},
   "source": [
    "# Try this with Dask First"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e94c06f",
   "metadata": {},
   "source": [
    "I'm going to try this firstly with Dask and then with Spark. I'm more confident in Dask than I am in Spark. It will also let us confirm our answer - triangulate the data so to speak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "350fdb9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03_test.ipynb\t       fhvhv\r\n",
      "04_pyspark.ipynb       fhvhv_tripdata_2021-01.csv\r\n",
      "05_taxi_schema.ipynb   fhvhv_tripdata_2021-01.csv.1\r\n",
      "06_spark_sql.ipynb     fhvhv_tripdata_2021-02.csv\r\n",
      "07_groupby_join.ipynb  fhvhv_tripdata_2021-02_homeworkQ3.ipynb\r\n",
      "08_rdds.ipynb\t       head.csv\r\n",
      "data\t\t       HomeworkQ3.ipynb\r\n",
      "download_data.sh       test.py\r\n"
     ]
    }
   ],
   "source": [
    "#just finding my exact file name here...\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fdfd6844",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a613d028",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'fhvhv_tripdata_2021-02.csv'\n",
    "df = dd.read_csv(filename, parse_dates=['pickup_datetime', 'dropoff_datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "502867b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hvfhs_license_num        object\n",
       "dispatching_base_num     object\n",
       "pickup_datetime          object\n",
       "dropoff_datetime         object\n",
       "PULocationID              int64\n",
       "DOLocationID              int64\n",
       "SR_Flag                 float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "cafd92d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new dataframe with only pickup_datetime on the 15h of February\n",
    "fifteen_Feb_df = df[(df.pickup_datetime >= '2021-02-15') &\n",
    "                    (df.pickup_datetime < '2021-02-16') ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2b5514b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_15_feb_df = fifteen_Feb_df.compute() #turn dask dataframe it into a pandas dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1411e578",
   "metadata": {},
   "source": [
    "# Answer in Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "845b94b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(367170, 7)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_15_feb_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "31ed4b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hvfhs_license_num</th>\n",
       "      <th>dispatching_base_num</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>SR_Flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>151549</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B02764</td>\n",
       "      <td>2021-02-15 00:14:30</td>\n",
       "      <td>2021-02-15 00:26:11</td>\n",
       "      <td>108</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151550</th>\n",
       "      <td>HV0005</td>\n",
       "      <td>B02510</td>\n",
       "      <td>2021-02-15 00:23:46</td>\n",
       "      <td>2021-02-15 00:41:09</td>\n",
       "      <td>37</td>\n",
       "      <td>61</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151551</th>\n",
       "      <td>HV0004</td>\n",
       "      <td>B02800</td>\n",
       "      <td>2021-02-15 00:34:20</td>\n",
       "      <td>2021-02-15 00:39:34</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151552</th>\n",
       "      <td>HV0004</td>\n",
       "      <td>B02800</td>\n",
       "      <td>2021-02-15 00:49:51</td>\n",
       "      <td>2021-02-15 01:10:29</td>\n",
       "      <td>138</td>\n",
       "      <td>239</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151553</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B02884</td>\n",
       "      <td>2021-02-15 00:03:13</td>\n",
       "      <td>2021-02-15 00:19:23</td>\n",
       "      <td>81</td>\n",
       "      <td>47</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151554</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B02884</td>\n",
       "      <td>2021-02-15 00:33:30</td>\n",
       "      <td>2021-02-15 00:46:24</td>\n",
       "      <td>69</td>\n",
       "      <td>243</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151555</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B02884</td>\n",
       "      <td>2021-02-15 00:49:01</td>\n",
       "      <td>2021-02-15 00:54:45</td>\n",
       "      <td>243</td>\n",
       "      <td>243</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151556</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B02884</td>\n",
       "      <td>2021-02-15 00:55:56</td>\n",
       "      <td>2021-02-15 01:04:04</td>\n",
       "      <td>127</td>\n",
       "      <td>116</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151557</th>\n",
       "      <td>HV0005</td>\n",
       "      <td>B02510</td>\n",
       "      <td>2021-02-15 00:03:57</td>\n",
       "      <td>2021-02-15 00:13:38</td>\n",
       "      <td>81</td>\n",
       "      <td>240</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151558</th>\n",
       "      <td>HV0005</td>\n",
       "      <td>B02510</td>\n",
       "      <td>2021-02-15 00:39:03</td>\n",
       "      <td>2021-02-15 00:46:41</td>\n",
       "      <td>259</td>\n",
       "      <td>259</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       hvfhs_license_num dispatching_base_num      pickup_datetime  \\\n",
       "151549            HV0003               B02764  2021-02-15 00:14:30   \n",
       "151550            HV0005               B02510  2021-02-15 00:23:46   \n",
       "151551            HV0004               B02800  2021-02-15 00:34:20   \n",
       "151552            HV0004               B02800  2021-02-15 00:49:51   \n",
       "151553            HV0003               B02884  2021-02-15 00:03:13   \n",
       "151554            HV0003               B02884  2021-02-15 00:33:30   \n",
       "151555            HV0003               B02884  2021-02-15 00:49:01   \n",
       "151556            HV0003               B02884  2021-02-15 00:55:56   \n",
       "151557            HV0005               B02510  2021-02-15 00:03:57   \n",
       "151558            HV0005               B02510  2021-02-15 00:39:03   \n",
       "\n",
       "           dropoff_datetime  PULocationID  DOLocationID  SR_Flag  \n",
       "151549  2021-02-15 00:26:11           108            22      NaN  \n",
       "151550  2021-02-15 00:41:09            37            61      NaN  \n",
       "151551  2021-02-15 00:39:34            82            82      NaN  \n",
       "151552  2021-02-15 01:10:29           138           239      NaN  \n",
       "151553  2021-02-15 00:19:23            81            47      NaN  \n",
       "151554  2021-02-15 00:46:24            69           243      NaN  \n",
       "151555  2021-02-15 00:54:45           243           243      NaN  \n",
       "151556  2021-02-15 01:04:04           127           116      NaN  \n",
       "151557  2021-02-15 00:13:38            81           240      NaN  \n",
       "151558  2021-02-15 00:46:41           259           259      NaN  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#just having a quick look at the data here...\n",
    "my_15_feb_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c81a7efd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hvfhs_license_num</th>\n",
       "      <th>dispatching_base_num</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>SR_Flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>518709</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B02866</td>\n",
       "      <td>2021-02-15 23:56:17</td>\n",
       "      <td>2021-02-16 00:09:05</td>\n",
       "      <td>186</td>\n",
       "      <td>146</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518710</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B02866</td>\n",
       "      <td>2021-02-15 23:06:59</td>\n",
       "      <td>2021-02-15 23:21:53</td>\n",
       "      <td>148</td>\n",
       "      <td>143</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518711</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B02866</td>\n",
       "      <td>2021-02-15 23:56:21</td>\n",
       "      <td>2021-02-16 00:04:42</td>\n",
       "      <td>79</td>\n",
       "      <td>125</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518712</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B02875</td>\n",
       "      <td>2021-02-15 23:02:04</td>\n",
       "      <td>2021-02-15 23:17:12</td>\n",
       "      <td>238</td>\n",
       "      <td>237</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518713</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B02875</td>\n",
       "      <td>2021-02-15 23:22:51</td>\n",
       "      <td>2021-02-15 23:28:15</td>\n",
       "      <td>237</td>\n",
       "      <td>233</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518714</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B02875</td>\n",
       "      <td>2021-02-15 23:38:19</td>\n",
       "      <td>2021-02-15 23:48:02</td>\n",
       "      <td>170</td>\n",
       "      <td>88</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518715</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B02765</td>\n",
       "      <td>2021-02-15 23:30:45</td>\n",
       "      <td>2021-02-16 00:02:46</td>\n",
       "      <td>65</td>\n",
       "      <td>91</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518716</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B02764</td>\n",
       "      <td>2021-02-15 23:16:13</td>\n",
       "      <td>2021-02-16 00:03:08</td>\n",
       "      <td>155</td>\n",
       "      <td>265</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518717</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B02764</td>\n",
       "      <td>2021-02-15 23:24:45</td>\n",
       "      <td>2021-02-15 23:51:05</td>\n",
       "      <td>225</td>\n",
       "      <td>92</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518718</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B02682</td>\n",
       "      <td>2021-02-15 23:22:15</td>\n",
       "      <td>2021-02-16 00:01:52</td>\n",
       "      <td>217</td>\n",
       "      <td>217</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       hvfhs_license_num dispatching_base_num      pickup_datetime  \\\n",
       "518709            HV0003               B02866  2021-02-15 23:56:17   \n",
       "518710            HV0003               B02866  2021-02-15 23:06:59   \n",
       "518711            HV0003               B02866  2021-02-15 23:56:21   \n",
       "518712            HV0003               B02875  2021-02-15 23:02:04   \n",
       "518713            HV0003               B02875  2021-02-15 23:22:51   \n",
       "518714            HV0003               B02875  2021-02-15 23:38:19   \n",
       "518715            HV0003               B02765  2021-02-15 23:30:45   \n",
       "518716            HV0003               B02764  2021-02-15 23:16:13   \n",
       "518717            HV0003               B02764  2021-02-15 23:24:45   \n",
       "518718            HV0003               B02682  2021-02-15 23:22:15   \n",
       "\n",
       "           dropoff_datetime  PULocationID  DOLocationID  SR_Flag  \n",
       "518709  2021-02-16 00:09:05           186           146      NaN  \n",
       "518710  2021-02-15 23:21:53           148           143      NaN  \n",
       "518711  2021-02-16 00:04:42            79           125      NaN  \n",
       "518712  2021-02-15 23:17:12           238           237      NaN  \n",
       "518713  2021-02-15 23:28:15           237           233      NaN  \n",
       "518714  2021-02-15 23:48:02           170            88      NaN  \n",
       "518715  2021-02-16 00:02:46            65            91      NaN  \n",
       "518716  2021-02-16 00:03:08           155           265      NaN  \n",
       "518717  2021-02-15 23:51:05           225            92      NaN  \n",
       "518718  2021-02-16 00:01:52           217           217      NaN  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_15_feb_df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a4d443",
   "metadata": {},
   "source": [
    "# Now try with pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "07de9dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ca5bbb06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/27 14:08:45 WARN Utils: Your hostname, sandy-ODYSSEY-X86J4105 resolves to a loopback address: 127.0.1.1; using 10.0.0.1 instead (on interface wlo2)\n",
      "22/02/27 14:08:45 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/sandy/spark/spark-3.0.3-bin-hadoop3.2/jars/spark-unsafe_2.12-3.0.3.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "22/02/27 14:08:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('fhvhv_tripdata_2021-02') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cf8de204",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!wget https://nyc-tlc.s3.amazonaws.com/trip+data/fhvhv_tripdata_2021-02.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2a52087c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wc -l fhvhv_tripdata_2021-02.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "16937bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fc61a99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = types.StructType([\n",
    "    types.StructField('hvfhs_license_num', types.StringType(), True),\n",
    "    types.StructField('dispatching_base_num', types.StringType(), True),\n",
    "    types.StructField('pickup_datetime', types.TimestampType(), True),\n",
    "    types.StructField('dropoff_datetime', types.TimestampType(), True),\n",
    "    types.StructField('PULocationID', types.IntegerType(), True),\n",
    "    types.StructField('DOLocationID', types.IntegerType(), True),\n",
    "    types.StructField('SR_Flag', types.StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ec05f6",
   "metadata": {},
   "source": [
    "I don't need to bother repartitioning etc. here as I've already done it before. I'll turn these code cells into markdown cells and simply start off from reading the parquet file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9698b4",
   "metadata": {},
   "source": [
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(schema) \\\n",
    "    .csv('fhvhv_tripdata_2021-02.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2f3c1a",
   "metadata": {},
   "source": [
    "df = df.repartition(24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27e3bfc",
   "metadata": {},
   "source": [
    "df.write.parquet('fhvhv/2021/02/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c3cab876",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet('fhvhv/2021/02/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "203b5627",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- hvfhs_license_num: string (nullable = true)\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropoff_datetime: timestamp (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- SR_Flag: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d0e47c",
   "metadata": {},
   "source": [
    "# Answer in Pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "84ea4a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 1:>                                                          (0 + 4) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|  367165|\n",
      "+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Register the DataFrame as a SQL temporary view\n",
    "df.createOrReplaceTempView(\"fhvhv_2021_02\")\n",
    "\n",
    "sqlDF = spark.sql(\"SELECT COUNT(1) \\\n",
    "                     FROM fhvhv_2021_02 \\\n",
    "                    WHERE pickup_datetime >= '2021-02-15' AND pickup_datetime < '2021-02-16'\")\n",
    "sqlDF.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
